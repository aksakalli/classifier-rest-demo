{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "The data is given without any explanation, so we don't have any intuition how it is collected and which heuristic can help us to come up with an accurate method. Thus, the variables needs to be investigated.\n",
    "\n",
    "CSV is formated with semicolon separator and European style decimal numbers with comma. We will create a DataFrame and do some exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/training.csv', sep=';', decimal=\",\")\n",
    "df_valid = pd.read_csv('../data/validation.csv', sep=';', decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v8</th>\n",
       "      <th>v11</th>\n",
       "      <th>v14</th>\n",
       "      <th>v15</th>\n",
       "      <th>v17</th>\n",
       "      <th>v19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3661.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>3.600000e+03</td>\n",
       "      <td>3700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.820713</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>3.439496</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>162.695000</td>\n",
       "      <td>2246.705946</td>\n",
       "      <td>1.626950e+06</td>\n",
       "      <td>0.925405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.666181</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>4.335229</td>\n",
       "      <td>6.750553</td>\n",
       "      <td>156.045682</td>\n",
       "      <td>8708.571126</td>\n",
       "      <td>1.560457e+06</td>\n",
       "      <td>0.262772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.670000</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.830000</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>1059.750000</td>\n",
       "      <td>2.800000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.250000</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1160.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.160000e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                v2           v3           v8          v11          v14  \\\n",
       "count  3661.000000  3700.000000  3700.000000  3700.000000  3600.000000   \n",
       "mean     32.820713     0.000585     3.439496     4.160000   162.695000   \n",
       "std      12.666181     0.000540     4.335229     6.750553   156.045682   \n",
       "min      13.750000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      23.000000     0.000150     0.500000     0.000000     0.000000   \n",
       "50%      28.670000     0.000425     1.750000     2.000000   120.000000   \n",
       "75%      40.830000     0.000963     5.000000     6.000000   280.000000   \n",
       "max      80.250000     0.002800    28.500000    67.000000  1160.000000   \n",
       "\n",
       "                 v15           v17          v19  \n",
       "count    3700.000000  3.600000e+03  3700.000000  \n",
       "mean     2246.705946  1.626950e+06     0.925405  \n",
       "std      8708.571126  1.560457e+06     0.262772  \n",
       "min         0.000000  0.000000e+00     0.000000  \n",
       "25%         0.000000  0.000000e+00     1.000000  \n",
       "50%       113.000000  1.200000e+06     1.000000  \n",
       "75%      1059.750000  2.800000e+06     1.000000  \n",
       "max    100000.000000  1.160000e+07     1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v19 is also a boolean variable and the rest are discreete.\n",
    "\n",
    "* **Discrete:** v1 v4 v5 v6 v7 v9(bool) v10(bool) v12(bool) v13 v18(NaN) v19(bool)\n",
    "* **Continues:** v2 v3 v8 v11 v14 v15 v17\n",
    "\n",
    "There are also some missing values to deal with. There are some approaches to do so:\n",
    "\n",
    "* discarding  (drop the column or row with NaN)\n",
    "* imputation (fill with a constant like )\n",
    "* using methods that can deal with these as an input (ANN,  the Gradient Boosting framework, ...)\n",
    "* ...\n",
    "\n",
    "Here are the number of `NaN` values per field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 39\n",
      "v2: 39\n",
      "v3: 0\n",
      "v4: 64\n",
      "v5: 64\n",
      "v6: 66\n",
      "v7: 66\n",
      "v8: 0\n",
      "v9: 0\n",
      "v10: 0\n",
      "v11: 0\n",
      "v12: 0\n",
      "v13: 0\n",
      "v14: 100\n",
      "v15: 0\n",
      "v17: 100\n",
      "v18: 2145\n",
      "v19: 0\n",
      "classLabel: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['v3', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v15', 'v19', 'classLabel']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_null = []\n",
    "for c in df.columns:\n",
    "    nulls = df[c].isna().sum()\n",
    "    if nulls==0:\n",
    "        not_null.append(c)\n",
    "    print(f'{c}: {nulls}')\n",
    "\n",
    "not_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to take into account about this dataset is that the target positive values are imbalanced. So _accuracy_ won't be a good performance metric for this problem. Since the ultimate objective is not clarrified, we will be using F1 metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes.    3424\n",
       "no.      276\n",
       "Name: classLabel, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['classLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "Before doing anything fancy, it is better to create a simple baseline for comparison. For this purpose, we will create a simple logistic regression classifier.\n",
    "\n",
    "Continues and not null fields do not require any preprocessing, let's check how it performs with a simple method in the training dataset with 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['v3', 'v8', 'v11', 'v15', 'v19']\n",
    "\n",
    "X = df[fields].values\n",
    "y = (df['classLabel'] == 'yes.').astype(int).values\n",
    "\n",
    "X_valid = df_valid[fields].values\n",
    "y_valid = (df_valid['classLabel'] == 'yes.').astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 100.00% (0.00%)\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression(solver='lbfgs', max_iter=500, random_state=seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "results = cross_val_score(estimator, X, y, cv=kfold, scoring='f1')\n",
    "print('Results: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['v19'] != (df['classLabel'] == 'yes.').astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apparently v19 field is equal to label in the training set, how about the accuracy for the validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48453608247422686\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X, y)\n",
    "y_valid_hat = model.predict(X_valid)\n",
    "print(f1_score(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite very high performance in the training, it performs poorly in the validation. There is a high bias in the training set in comparison to the validation. \n",
    "\n",
    "## Balancing Train and Test\n",
    "\n",
    "It could be the reason that the second CSV file is collected in a different settings. It is something similar to **MNIST** vs **NIST** (the original dataset) case where samples are collected from different places. Thus, we need to merge two sets and normalize for training our model.\n",
    "\n",
    "We will conduct another experiment with the simple classifier. First, the discrete variables need to be defined as dummy or a single 1/0 variable. Since logistic regression estimator can not work with `NaN` values, they will be filled as zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_discrete_vars(df):\n",
    "    \n",
    "    # not null and binary strings can be a single 1/0 value\n",
    "    bin_strs = ['v9', 'v10', 'v12']\n",
    "    for col in bin_strs:\n",
    "        df[col] = (df[col]=='t').astype(int)\n",
    "    \n",
    "    other_discrete_vars = ['v1', 'v4', 'v5', 'v6', 'v7', 'v13', 'v18']\n",
    "\n",
    "    for col in other_discrete_vars:\n",
    "        dummies = pd.get_dummies(df[col], prefix=col)\n",
    "        df = pd.concat([df.drop([col], axis=1), dummies], axis=1)\n",
    "        \n",
    "    \n",
    "    return df\n",
    "\n",
    "df = pd.concat([df, df_valid])\n",
    "df = prepare_discrete_vars(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 94.89% (0.11%)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['classLabel'], axis=1).fillna(0).values\n",
    "y = (df['classLabel'] == 'yes.').astype(int).values\n",
    "\n",
    "estimator = LogisticRegression(solver='lbfgs', max_iter=500, random_state=seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold, scoring='f1')\n",
    "print('Results: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the biased validation set is only 5% of the dataset, this performance is not quite satisfactory. A better performance can be achieved by using a more robust method which can take NaN values as an input: the Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05128205128205128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_valid)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 99.15% (0.27%)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "fields = ['v2', 'v3', 'v8', 'v9', 'v10', 'v11', 'v12', 'v14', 'v15', 'v17', 'v19',\n",
    "       'v1_a', 'v1_b', 'v4_l', 'v4_u', 'v4_y', 'v5_g', 'v5_gg',\n",
    "       'v5_p', 'v6_W', 'v6_aa', 'v6_c', 'v6_cc', 'v6_d', 'v6_e', 'v6_ff',\n",
    "       'v6_i', 'v6_j', 'v6_k', 'v6_m', 'v6_q', 'v6_r', 'v6_x', 'v7_bb',\n",
    "       'v7_dd', 'v7_ff', 'v7_h', 'v7_j', 'v7_n', 'v7_o', 'v7_v', 'v7_z',\n",
    "       'v13_g', 'v13_p', 'v13_s', 'v18_f', 'v18_t']\n",
    "\n",
    "X = df[fields].fillna(0).values\n",
    "y = (df['classLabel'] == 'yes.').astype(int).values\n",
    "\n",
    "estimator = XGBClassifier()\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold, scoring='f1')\n",
    "print('Results: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite satisfactory! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
